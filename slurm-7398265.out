/var/spool/slurm/job7398265/slurm_script:9: command not found: module

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.


/home/amohanpa/.conda/envs/cent7/2020.11-py38/Generation/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/home/amohanpa/.conda/envs/cent7/2020.11-py38/Generation/lib/python3.10/site-packages/transformers/utils/hub.py:123: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/home/amohanpa/.conda/envs/cent7/2020.11-py38/Generation/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/home/amohanpa/.conda/envs/cent7/2020.11-py38/Generation/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.
  _torch_pytree._register_pytree_node(
/home/amohanpa/transformers/examples/pytorch/audio-classification/run_audio_classification.py:218: FutureWarning: The argument `--freeze_feature_extractor` is deprecated and will be removed in a future version. Use `--freeze_feature_encoder` instead. Setting `freeze_feature_encoder==True`.
  warnings.warn(
11/13/2024 15:23:12 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: False
11/13/2024 15:23:12 - INFO - __main__ - Training/evaluation parameters TrainingArguments(
_n_gpu=1,
adafactor=False,
adam_beta1=0.9,
adam_beta2=0.999,
adam_epsilon=1e-08,
auto_find_batch_size=False,
bf16=False,
bf16_full_eval=False,
data_seed=None,
dataloader_drop_last=False,
dataloader_num_workers=1,
dataloader_persistent_workers=False,
dataloader_pin_memory=True,
ddp_backend=None,
ddp_broadcast_buffers=None,
ddp_bucket_cap_mb=None,
ddp_find_unused_parameters=None,
ddp_timeout=1800,
debug=[],
deepspeed=None,
disable_tqdm=False,
dispatch_batches=None,
do_eval=True,
do_predict=False,
do_train=False,
eval_accumulation_steps=None,
eval_delay=0,
eval_steps=None,
evaluation_strategy=epoch,
fp16=False,
fp16_backend=auto,
fp16_full_eval=False,
fp16_opt_level=O1,
fsdp=[],
fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},
fsdp_min_num_params=0,
fsdp_transformer_layer_cls_to_wrap=None,
full_determinism=False,
gradient_accumulation_steps=1,
gradient_checkpointing=False,
gradient_checkpointing_kwargs=None,
greater_is_better=True,
group_by_length=False,
half_precision_backend=auto,
hub_always_push=False,
hub_model_id=None,
hub_private_repo=False,
hub_strategy=every_save,
hub_token=<HUB_TOKEN>,
ignore_data_skip=False,
include_inputs_for_metrics=False,
include_num_input_tokens_seen=False,
include_tokens_per_second=False,
jit_mode_eval=False,
label_names=None,
label_smoothing_factor=0.0,
learning_rate=1e-05,
length_column_name=length,
load_best_model_at_end=True,
local_rank=0,
log_level=passive,
log_level_replica=warning,
log_on_each_node=True,
logging_dir=/scratch/gilbreth/amohanpa/Whisper-tiny/Trial/runs/Nov13_15-23-10_gilbreth-m001.rcac.purdue.edu,
logging_first_step=False,
logging_nan_inf_filter=True,
logging_steps=10,
logging_strategy=steps,
lr_scheduler_kwargs={},
lr_scheduler_type=linear,
max_grad_norm=1.0,
max_steps=-1,
metric_for_best_model=accuracy,
mp_parameters=,
neftune_noise_alpha=None,
no_cuda=False,
num_train_epochs=10.0,
optim=adamw_torch,
optim_args=None,
output_dir=/scratch/gilbreth/amohanpa/Whisper-tiny/Trial,
overwrite_output_dir=True,
past_index=-1,
per_device_eval_batch_size=32,
per_device_train_batch_size=32,
prediction_loss_only=False,
push_to_hub=False,
push_to_hub_model_id=None,
push_to_hub_organization=None,
push_to_hub_token=<PUSH_TO_HUB_TOKEN>,
ray_scope=last,
remove_unused_columns=False,
report_to=['wandb'],
resume_from_checkpoint=None,
run_name=/scratch/gilbreth/amohanpa/Whisper-tiny/Trial,
save_on_each_node=False,
save_only_model=False,
save_safetensors=True,
save_steps=500,
save_strategy=epoch,
save_total_limit=3,
seed=0,
skip_memory_metrics=True,
split_batches=False,
tf32=None,
torch_compile=False,
torch_compile_backend=None,
torch_compile_mode=None,
torchdynamo=None,
tpu_metrics_debug=False,
tpu_num_cores=None,
use_cpu=False,
use_ipex=False,
use_legacy_prediction_loop=False,
use_mps_device=False,
warmup_ratio=0.1,
warmup_steps=0,
weight_decay=0.0,
)
/home/amohanpa/.conda/envs/cent7/2020.11-py38/Generation/lib/python3.10/site-packages/datasets/load.py:1454: FutureWarning: The repository for superb contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/superb
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
[INFO|feature_extraction_utils.py:535] 2024-11-13 15:23:15,491 >> loading configuration file /scratch/gilbreth/amohanpa/Whisper-tiny/ks/preprocessor_config.json
[INFO|feature_extraction_utils.py:579] 2024-11-13 15:23:15,494 >> Feature extractor WhisperFeatureExtractor {
  "chunk_length": 30,
  "feature_extractor_type": "WhisperFeatureExtractor",
  "feature_size": 80,
  "hop_length": 160,
  "n_fft": 400,
  "n_samples": 480000,
  "nb_max_frames": 3000,
  "padding_side": "right",
  "padding_value": 0.0,
  "processor_class": "WhisperProcessor",
  "return_attention_mask": false,
  "sampling_rate": 16000
}

[INFO|configuration_utils.py:737] 2024-11-13 15:23:15,862 >> loading configuration file /scratch/gilbreth/amohanpa/Whisper-tiny/ks/config.json
[INFO|configuration_utils.py:802] 2024-11-13 15:23:15,868 >> Model config WhisperConfig {
  "_name_or_path": "/scratch/gilbreth/amohanpa/Whisper-tiny/ks",
  "activation_dropout": 0.0,
  "activation_function": "gelu",
  "apply_spec_augment": false,
  "architectures": [
    "WhisperForAudioClassification"
  ],
  "attention_dropout": 0.0,
  "begin_suppress_tokens": [
    220,
    50257
  ],
  "bos_token_id": 50257,
  "classifier_proj_size": 256,
  "d_model": 384,
  "decoder_attention_heads": 6,
  "decoder_ffn_dim": 1536,
  "decoder_layerdrop": 0.0,
  "decoder_layers": 4,
  "decoder_start_token_id": 50258,
  "dropout": 0.0,
  "encoder_attention_heads": 6,
  "encoder_ffn_dim": 1536,
  "encoder_layerdrop": 0.0,
  "encoder_layers": 4,
  "eos_token_id": 50257,
  "finetuning_task": "audio-classification",
  "forced_decoder_ids": [
    [
      1,
      50259
    ],
    [
      2,
      50359
    ],
    [
      3,
      50363
    ]
  ],
  "id2label": {
    "0": "yes",
    "1": "no",
    "10": "_silence_",
    "11": "_unknown_",
    "2": "up",
    "3": "down",
    "4": "left",
    "5": "right",
    "6": "on",
    "7": "off",
    "8": "stop",
    "9": "go"
  },
  "init_std": 0.02,
  "is_encoder_decoder": true,
  "label2id": {
    "_silence_": "10",
    "_unknown_": "11",
    "down": "3",
    "go": "9",
    "left": "4",
    "no": "1",
    "off": "7",
    "on": "6",
    "right": "5",
    "stop": "8",
    "up": "2",
    "yes": "0"
  },
  "mask_feature_length": 10,
  "mask_feature_min_masks": 0,
  "mask_feature_prob": 0.0,
  "mask_time_length": 10,
  "mask_time_min_masks": 2,
  "mask_time_prob": 0.05,
  "max_length": 448,
  "max_source_positions": 1500,
  "max_target_positions": 448,
  "median_filter_width": 7,
  "model_type": "whisper",
  "num_hidden_layers": 4,
  "num_mel_bins": 80,
  "pad_token_id": 50257,
  "scale_embedding": false,
  "suppress_tokens": [
    1,
    2,
    7,
    8,
    9,
    10,
    14,
    25,
    26,
    27,
    28,
    29,
    31,
    58,
    59,
    60,
    61,
    62,
    63,
    90,
    91,
    92,
    93,
    359,
    503,
    522,
    542,
    873,
    893,
    902,
    918,
    922,
    931,
    1350,
    1853,
    1982,
    2460,
    2627,
    3246,
    3253,
    3268,
    3536,
    3846,
    3961,
    4183,
    4667,
    6585,
    6647,
    7273,
    9061,
    9383,
    10428,
    10929,
    11938,
    12033,
    12331,
    12562,
    13793,
    14157,
    14635,
    15265,
    15618,
    16553,
    16604,
    18362,
    18956,
    20075,
    21675,
    22520,
    26130,
    26161,
    26435,
    28279,
    29464,
    31650,
    32302,
    32470,
    36865,
    42863,
    47425,
    49870,
    50254,
    50258,
    50358,
    50359,
    50360,
    50361,
    50362
  ],
  "torch_dtype": "float32",
  "transformers_version": "4.36.0",
  "use_cache": true,
  "use_weighted_layer_sum": false,
  "vocab_size": 51865
}

[INFO|modeling_utils.py:3329] 2024-11-13 15:23:15,903 >> loading weights file /scratch/gilbreth/amohanpa/Whisper-tiny/ks/model.safetensors
[WARNING|modeling_utils.py:4163] 2024-11-13 15:23:17,023 >> Some weights of the model checkpoint at /scratch/gilbreth/amohanpa/Whisper-tiny/ks were not used when initializing WhisperForAudioClassification: ['encoder.layers.1.self_attn.softmax_16.5.1.weight', 'encoder.layers.1.self_attn.softmax_16.3.3.bias', 'encoder.layers.0.self_attn.softmax_16.4.3.bias', 'encoder.layers.1.self_attn.softmax_16.4.1.weight', 'encoder.layers.1.self_attn.softmax_16.2.3.weight', 'encoder.layers.0.self_attn.softmax_16.0.1.bias', 'encoder.layers.1.self_attn.softmax_16.0.1.bias', 'encoder.layers.0.self_attn.softmax_16.0.3.weight', 'encoder.layers.2.self_attn.softmax_16.5.3.bias', 'encoder.layers.3.self_attn.softmax_16.3.1.bias', 'encoder.layers.2.self_attn.softmax_16.4.1.bias', 'encoder.layers.0.self_attn.softmax_16.2.1.weight', 'encoder.layers.0.self_attn.softmax_16.5.1.weight', 'encoder.layers.3.self_attn.softmax_16.4.3.weight', 'encoder.layers.3.self_attn.softmax_16.0.3.bias', 'encoder.layers.2.self_attn.softmax_16.1.3.weight', 'encoder.layers.2.self_attn.softmax_16.2.1.bias', 'encoder.layers.0.self_attn.softmax_16.5.1.bias', 'encoder.layers.1.self_attn.softmax_16.0.3.weight', 'encoder.layers.1.self_attn.softmax_16.1.1.weight', 'encoder.layers.2.self_attn.softmax_16.4.1.weight', 'encoder.layers.3.self_attn.softmax_16.5.1.bias', 'encoder.layers.2.self_attn.softmax_16.2.3.weight', 'encoder.layers.3.self_attn.softmax_16.4.3.bias', 'encoder.layers.3.self_attn.softmax_16.2.3.weight', 'encoder.layers.3.self_attn.softmax_16.2.1.weight', 'encoder.layers.3.self_attn.softmax_16.0.3.weight', 'encoder.layers.3.self_attn.softmax_16.1.3.weight', 'encoder.layers.0.self_attn.softmax_16.3.1.weight', 'encoder.layers.1.self_attn.softmax_16.2.3.bias', 'encoder.layers.3.self_attn.softmax_16.4.1.bias', 'encoder.layers.1.self_attn.softmax_16.4.1.bias', 'encoder.layers.0.self_attn.softmax_16.0.3.bias', 'encoder.layers.2.self_attn.softmax_16.3.3.bias', 'encoder.layers.3.self_attn.softmax_16.1.3.bias', 'encoder.layers.2.self_attn.softmax_16.0.3.bias', 'encoder.layers.0.self_attn.softmax_16.0.1.weight', 'encoder.layers.3.self_attn.softmax_16.5.3.bias', 'encoder.layers.0.self_attn.softmax_16.3.3.bias', 'encoder.layers.1.self_attn.softmax_16.0.3.bias', 'encoder.layers.0.self_attn.softmax_16.1.1.bias', 'encoder.layers.0.self_attn.softmax_16.2.1.bias', 'encoder.layers.2.self_attn.softmax_16.2.1.weight', 'encoder.layers.1.self_attn.softmax_16.0.1.weight', 'encoder.layers.3.self_attn.softmax_16.5.3.weight', 'encoder.layers.2.self_attn.softmax_16.0.1.bias', 'encoder.layers.0.self_attn.softmax_16.5.3.weight', 'encoder.layers.3.self_attn.softmax_16.0.1.weight', 'encoder.layers.1.self_attn.softmax_16.5.3.bias', 'encoder.layers.0.self_attn.softmax_16.1.3.bias', 'encoder.layers.3.self_attn.softmax_16.3.1.weight', 'encoder.layers.3.self_attn.softmax_16.3.3.bias', 'encoder.layers.2.self_attn.softmax_16.3.1.weight', 'encoder.layers.0.self_attn.softmax_16.4.1.weight', 'encoder.layers.1.self_attn.softmax_16.2.1.weight', 'encoder.layers.0.self_attn.softmax_16.1.3.weight', 'encoder.layers.0.self_attn.softmax_16.3.1.bias', 'encoder.layers.1.self_attn.softmax_16.5.3.weight', 'encoder.layers.0.self_attn.softmax_16.5.3.bias', 'encoder.layers.1.self_attn.softmax_16.4.3.bias', 'encoder.layers.2.self_attn.softmax_16.5.1.bias', 'encoder.layers.3.self_attn.softmax_16.1.1.weight', 'encoder.layers.0.self_attn.softmax_16.1.1.weight', 'encoder.layers.3.self_attn.softmax_16.0.1.bias', 'encoder.layers.1.self_attn.softmax_16.3.1.bias', 'encoder.layers.2.self_attn.softmax_16.0.1.weight', 'encoder.layers.0.self_attn.softmax_16.4.1.bias', 'encoder.layers.0.self_attn.softmax_16.4.3.weight', 'encoder.layers.1.self_attn.softmax_16.1.1.bias', 'encoder.layers.1.self_attn.softmax_16.1.3.weight', 'encoder.layers.2.self_attn.softmax_16.5.3.weight', 'encoder.layers.1.self_attn.softmax_16.4.3.weight', 'encoder.layers.0.self_attn.softmax_16.2.3.bias', 'encoder.layers.1.self_attn.softmax_16.3.1.weight', 'encoder.layers.0.self_attn.softmax_16.2.3.weight', 'encoder.layers.1.self_attn.softmax_16.1.3.bias', 'encoder.layers.3.self_attn.softmax_16.2.1.bias', 'encoder.layers.2.self_attn.softmax_16.4.3.bias', 'encoder.layers.2.self_attn.softmax_16.4.3.weight', 'encoder.layers.2.self_attn.softmax_16.5.1.weight', 'encoder.layers.2.self_attn.softmax_16.0.3.weight', 'encoder.layers.2.self_attn.softmax_16.2.3.bias', 'encoder.layers.1.self_attn.softmax_16.5.1.bias', 'encoder.layers.2.self_attn.softmax_16.1.1.bias', 'encoder.layers.3.self_attn.softmax_16.3.3.weight', 'encoder.layers.1.self_attn.softmax_16.3.3.weight', 'encoder.layers.2.self_attn.softmax_16.1.1.weight', 'encoder.layers.1.self_attn.softmax_16.2.1.bias', 'encoder.layers.3.self_attn.softmax_16.2.3.bias', 'encoder.layers.2.self_attn.softmax_16.1.3.bias', 'encoder.layers.2.self_attn.softmax_16.3.1.bias', 'encoder.layers.3.self_attn.softmax_16.5.1.weight', 'encoder.layers.3.self_attn.softmax_16.1.1.bias', 'encoder.layers.3.self_attn.softmax_16.4.1.weight', 'encoder.layers.2.self_attn.softmax_16.3.3.weight', 'encoder.layers.0.self_attn.softmax_16.3.3.weight']
- This IS expected if you are initializing WhisperForAudioClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing WhisperForAudioClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
[WARNING|modeling_utils.py:4175] 2024-11-13 15:23:17,023 >> Some weights of WhisperForAudioClassification were not initialized from the model checkpoint at /scratch/gilbreth/amohanpa/Whisper-tiny/ks and are newly initialized: ['encoder.layers.2.self_attn.softmax_16.3.0.bias', 'encoder.layers.0.self_attn.softmax_16.5.0.bias', 'encoder.layers.1.self_attn.softmax_16.1.0.bias', 'encoder.layers.2.self_attn.softmax_16.1.0.bias', 'encoder.layers.0.self_attn.softmax_16.2.0.weight', 'encoder.layers.0.self_attn.softmax_16.1.0.weight', 'encoder.layers.1.self_attn.softmax_16.0.0.weight', 'encoder.layers.1.self_attn.softmax_16.5.0.weight', 'encoder.layers.0.self_attn.softmax_16.0.0.weight', 'encoder.layers.0.self_attn.softmax_16.3.0.bias', 'encoder.layers.2.self_attn.softmax_16.0.0.weight', 'encoder.layers.2.self_attn.softmax_16.5.0.weight', 'encoder.layers.3.self_attn.softmax_16.5.0.bias', 'encoder.layers.3.self_attn.softmax_16.1.0.weight', 'encoder.layers.0.self_attn.softmax_16.3.0.weight', 'encoder.layers.3.self_attn.softmax_16.4.0.weight', 'encoder.layers.2.self_attn.softmax_16.2.0.weight', 'encoder.layers.0.self_attn.softmax_16.2.0.bias', 'encoder.layers.3.self_attn.softmax_16.1.0.bias', 'encoder.layers.0.self_attn.softmax_16.1.0.bias', 'encoder.layers.1.self_attn.softmax_16.1.0.weight', 'encoder.layers.2.self_attn.softmax_16.1.0.weight', 'encoder.layers.3.self_attn.softmax_16.3.0.weight', 'encoder.layers.0.self_attn.softmax_16.0.0.bias', 'encoder.layers.3.self_attn.softmax_16.2.0.weight', 'encoder.layers.1.self_attn.softmax_16.3.0.bias', 'encoder.layers.0.self_attn.softmax_16.4.0.bias', 'encoder.layers.1.self_attn.softmax_16.5.0.bias', 'encoder.layers.2.self_attn.softmax_16.0.0.bias', 'encoder.layers.1.self_attn.softmax_16.4.0.weight', 'encoder.layers.3.self_attn.softmax_16.4.0.bias', 'encoder.layers.3.self_attn.softmax_16.0.0.bias', 'encoder.layers.3.self_attn.softmax_16.2.0.bias', 'encoder.layers.1.self_attn.softmax_16.4.0.bias', 'encoder.layers.0.self_attn.softmax_16.4.0.weight', 'encoder.layers.3.self_attn.softmax_16.3.0.bias', 'encoder.layers.0.self_attn.softmax_16.5.0.weight', 'encoder.layers.1.self_attn.softmax_16.3.0.weight', 'encoder.layers.1.self_attn.softmax_16.2.0.weight', 'encoder.layers.2.self_attn.softmax_16.4.0.weight', 'encoder.layers.3.self_attn.softmax_16.0.0.weight', 'encoder.layers.3.self_attn.softmax_16.5.0.weight', 'encoder.layers.1.self_attn.softmax_16.0.0.bias', 'encoder.layers.2.self_attn.softmax_16.3.0.weight', 'encoder.layers.2.self_attn.softmax_16.4.0.bias', 'encoder.layers.2.self_attn.softmax_16.2.0.bias', 'encoder.layers.2.self_attn.softmax_16.5.0.bias', 'encoder.layers.1.self_attn.softmax_16.2.0.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
0
1
2
3
4
5
6
7
8
9
10
11
51094
6798
11/13/2024 15:23:17 - WARNING - accelerate.utils.other - Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[INFO|trainer.py:3207] 2024-11-13 15:23:18,138 >> ***** Running Evaluation *****
[INFO|trainer.py:3209] 2024-11-13 15:23:18,138 >>   Num examples = 6798
[INFO|trainer.py:3212] 2024-11-13 15:23:18,138 >>   Batch size = 32
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
  0%|          | 0/213 [00:00<?, ?it/s]  1%|          | 2/213 [00:00<00:52,  3.98it/s]  1%|▏         | 3/213 [00:01<01:33,  2.25it/s]  2%|▏         | 4/213 [00:01<01:55,  1.81it/s]  2%|▏         | 5/213 [00:02<02:08,  1.62it/s]  3%|▎         | 6/213 [00:03<02:16,  1.51it/s]  3%|▎         | 7/213 [00:04<02:21,  1.45it/s]  4%|▍         | 8/213 [00:04<02:24,  1.42it/s]  4%|▍         | 9/213 [00:05<02:26,  1.40it/s]  5%|▍         | 10/213 [00:06<02:26,  1.38it/s]  5%|▌         | 11/213 [00:07<02:27,  1.37it/s]  6%|▌         | 12/213 [00:07<02:28,  1.35it/s]  6%|▌         | 13/213 [00:08<02:28,  1.35it/s]  7%|▋         | 14/213 [00:09<02:27,  1.35it/s]  7%|▋         | 15/213 [00:10<02:26,  1.35it/s]  8%|▊         | 16/213 [00:10<02:25,  1.35it/s]  8%|▊         | 17/213 [00:11<02:24,  1.36it/s]  8%|▊         | 18/213 [00:12<02:23,  1.36it/s]  9%|▉         | 19/213 [00:13<02:22,  1.36it/s]  9%|▉         | 20/213 [00:13<02:22,  1.35it/s] 10%|▉         | 21/213 [00:14<02:22,  1.35it/s] 10%|█         | 22/213 [00:15<02:21,  1.35it/s] 11%|█         | 23/213 [00:16<02:20,  1.35it/s] 11%|█▏        | 24/213 [00:16<02:19,  1.35it/s] 12%|█▏        | 25/213 [00:17<02:18,  1.35it/s] 12%|█▏        | 26/213 [00:18<02:18,  1.35it/s] 13%|█▎        | 27/213 [00:18<02:16,  1.36it/s] 13%|█▎        | 28/213 [00:19<02:15,  1.36it/s] 14%|█▎        | 29/213 [00:20<02:14,  1.36it/s] 14%|█▍        | 30/213 [00:21<02:16,  1.34it/s] 15%|█▍        | 31/213 [00:21<02:16,  1.34it/s] 15%|█▌        | 32/213 [00:22<02:14,  1.35it/s] 15%|█▌        | 33/213 [00:23<02:12,  1.36it/s] 16%|█▌        | 34/213 [00:24<02:11,  1.36it/s] 16%|█▋        | 35/213 [00:24<02:10,  1.36it/s] 17%|█▋        | 36/213 [00:25<02:09,  1.37it/s] 17%|█▋        | 37/213 [00:26<02:09,  1.36it/s] 18%|█▊        | 38/213 [00:27<02:08,  1.37it/s] 18%|█▊        | 39/213 [00:27<02:07,  1.36it/s] 19%|█▉        | 40/213 [00:28<02:06,  1.37it/s] 19%|█▉        | 41/213 [00:29<02:06,  1.36it/s] 20%|█▉        | 42/213 [00:30<02:05,  1.37it/s] 20%|██        | 43/213 [00:30<02:04,  1.37it/s] 21%|██        | 44/213 [00:31<02:03,  1.37it/s] 21%|██        | 45/213 [00:32<02:02,  1.37it/s] 22%|██▏       | 46/213 [00:32<02:02,  1.37it/s] 22%|██▏       | 47/213 [00:33<02:01,  1.36it/s] 23%|██▎       | 48/213 [00:34<02:00,  1.36it/s] 23%|██▎       | 49/213 [00:35<01:59,  1.37it/s] 23%|██▎       | 50/213 [00:35<01:58,  1.37it/s] 24%|██▍       | 51/213 [00:36<01:59,  1.36it/s] 24%|██▍       | 52/213 [00:37<01:58,  1.36it/s] 25%|██▍       | 53/213 [00:38<01:57,  1.37it/s] 25%|██▌       | 54/213 [00:38<01:56,  1.36it/s] 26%|██▌       | 55/213 [00:39<01:55,  1.36it/s] 26%|██▋       | 56/213 [00:40<01:55,  1.36it/s] 27%|██▋       | 57/213 [00:40<01:53,  1.37it/s] 27%|██▋       | 58/213 [00:41<01:52,  1.37it/s] 28%|██▊       | 59/213 [00:42<01:52,  1.37it/s] 28%|██▊       | 60/213 [00:43<01:51,  1.37it/s] 29%|██▊       | 61/213 [00:43<01:51,  1.37it/s] 29%|██▉       | 62/213 [00:44<01:51,  1.35it/s] 30%|██▉       | 63/213 [00:45<01:50,  1.36it/s] 30%|███       | 64/213 [00:46<01:49,  1.36it/s] 31%|███       | 65/213 [00:46<01:48,  1.36it/s] 31%|███       | 66/213 [00:47<01:47,  1.36it/s] 31%|███▏      | 67/213 [00:48<01:46,  1.37it/s] 32%|███▏      | 68/213 [00:49<01:46,  1.36it/s] 32%|███▏      | 69/213 [00:49<01:46,  1.36it/s] 33%|███▎      | 70/213 [00:50<01:45,  1.36it/s] 33%|███▎      | 71/213 [00:51<01:44,  1.36it/s] 34%|███▍      | 72/213 [00:52<01:43,  1.36it/s] 34%|███▍      | 73/213 [00:52<01:43,  1.36it/s] 35%|███▍      | 74/213 [00:53<01:43,  1.35it/s] 35%|███▌      | 75/213 [00:54<01:42,  1.35it/s] 36%|███▌      | 76/213 [00:54<01:41,  1.35it/s] 36%|███▌      | 77/213 [00:55<01:40,  1.36it/s] 37%|███▋      | 78/213 [00:56<01:39,  1.36it/s] 37%|███▋      | 79/213 [00:57<01:38,  1.36it/s] 38%|███▊      | 80/213 [00:57<01:37,  1.37it/s] 38%|███▊      | 81/213 [00:58<01:36,  1.36it/s] 38%|███▊      | 82/213 [00:59<01:36,  1.36it/s] 39%|███▉      | 83/213 [01:00<01:35,  1.36it/s] 39%|███▉      | 84/213 [01:00<01:34,  1.36it/s] 40%|███▉      | 85/213 [01:01<01:34,  1.36it/s] 40%|████      | 86/213 [01:02<01:34,  1.34it/s] 41%|████      | 87/213 [01:03<01:33,  1.35it/s] 41%|████▏     | 88/213 [01:03<01:32,  1.35it/s] 42%|████▏     | 89/213 [01:04<01:31,  1.36it/s] 42%|████▏     | 90/213 [01:05<01:30,  1.36it/s] 43%|████▎     | 91/213 [01:06<01:29,  1.37it/s] 43%|████▎     | 92/213 [01:06<01:28,  1.37it/s] 44%|████▎     | 93/213 [01:07<01:28,  1.36it/s] 44%|████▍     | 94/213 [01:08<01:27,  1.36it/s] 45%|████▍     | 95/213 [01:08<01:26,  1.37it/s] 45%|████▌     | 96/213 [01:09<01:25,  1.37it/s] 46%|████▌     | 97/213 [01:10<01:24,  1.37it/s] 46%|████▌     | 98/213 [01:11<01:24,  1.37it/s] 46%|████▋     | 99/213 [01:11<01:23,  1.37it/s] 47%|████▋     | 100/213 [01:12<01:22,  1.37it/s] 47%|████▋     | 101/213 [01:13<01:24,  1.33it/s] 48%|████▊     | 102/213 [01:14<01:22,  1.34it/s] 48%|████▊     | 103/213 [01:14<01:21,  1.35it/s] 49%|████▉     | 104/213 [01:15<01:20,  1.35it/s] 49%|████▉     | 105/213 [01:16<01:19,  1.36it/s] 50%|████▉     | 106/213 [01:17<01:18,  1.36it/s] 50%|█████     | 107/213 [01:17<01:17,  1.37it/s] 51%|█████     | 108/213 [01:18<01:16,  1.37it/s] 51%|█████     | 109/213 [01:19<01:16,  1.36it/s] 52%|█████▏    | 110/213 [01:19<01:15,  1.36it/s] 52%|█████▏    | 111/213 [01:20<01:14,  1.36it/s] 53%|█████▎    | 112/213 [01:21<01:14,  1.36it/s] 53%|█████▎    | 113/213 [01:22<01:13,  1.36it/s] 54%|█████▎    | 114/213 [01:22<01:12,  1.36it/s] 54%|█████▍    | 115/213 [01:23<01:11,  1.37it/s] 54%|█████▍    | 116/213 [01:24<01:10,  1.37it/s] 55%|█████▍    | 117/213 [01:25<01:10,  1.37it/s] 55%|█████▌    | 118/213 [01:25<01:09,  1.36it/s] 56%|█████▌    | 119/213 [01:26<01:10,  1.34it/s] 56%|█████▋    | 120/213 [01:27<01:09,  1.35it/s] 57%|█████▋    | 121/213 [01:28<01:07,  1.35it/s] 57%|█████▋    | 122/213 [01:28<01:06,  1.36it/s] 58%|█████▊    | 123/213 [01:29<01:06,  1.36it/s] 58%|█████▊    | 124/213 [01:30<01:05,  1.36it/s] 59%|█████▊    | 125/213 [01:31<01:04,  1.36it/s] 59%|█████▉    | 126/213 [01:31<01:04,  1.36it/s] 60%|█████▉    | 127/213 [01:32<01:03,  1.36it/s] 60%|██████    | 128/213 [01:33<01:02,  1.36it/s] 61%|██████    | 129/213 [01:33<01:01,  1.36it/s] 61%|██████    | 130/213 [01:34<01:00,  1.36it/s] 62%|██████▏   | 131/213 [01:35<01:00,  1.36it/s] 62%|██████▏   | 132/213 [01:36<00:59,  1.36it/s] 62%|██████▏   | 133/213 [01:36<00:59,  1.36it/s] 63%|██████▎   | 134/213 [01:37<00:58,  1.35it/s] 63%|██████▎   | 135/213 [01:38<00:57,  1.35it/s] 64%|██████▍   | 136/213 [01:39<00:56,  1.35it/s] 64%|██████▍   | 137/213 [01:39<00:56,  1.35it/s] 65%|██████▍   | 138/213 [01:40<00:55,  1.36it/s] 65%|██████▌   | 139/213 [01:41<00:54,  1.36it/s] 66%|██████▌   | 140/213 [01:42<00:53,  1.37it/s] 66%|██████▌   | 141/213 [01:42<00:52,  1.36it/s] 67%|██████▋   | 142/213 [01:43<00:52,  1.36it/s] 67%|██████▋   | 143/213 [01:44<00:51,  1.37it/s] 68%|██████▊   | 144/213 [01:44<00:50,  1.37it/s] 68%|██████▊   | 145/213 [01:45<00:50,  1.35it/s] 69%|██████▊   | 146/213 [01:46<00:49,  1.34it/s] 69%|██████▉   | 147/213 [01:47<00:48,  1.35it/s] 69%|██████▉   | 148/213 [01:47<00:47,  1.36it/s] 70%|██████▉   | 149/213 [01:48<00:47,  1.36it/s] 70%|███████   | 150/213 [01:49<00:46,  1.37it/s] 71%|███████   | 151/213 [01:50<00:45,  1.37it/s] 71%|███████▏  | 152/213 [01:50<00:44,  1.37it/s] 72%|███████▏  | 153/213 [01:51<00:43,  1.37it/s] 72%|███████▏  | 154/213 [01:52<00:43,  1.37it/s] 73%|███████▎  | 155/213 [01:53<00:42,  1.36it/s] 73%|███████▎  | 156/213 [01:53<00:41,  1.36it/s] 74%|███████▎  | 157/213 [01:54<00:41,  1.37it/s] 74%|███████▍  | 158/213 [01:55<00:40,  1.37it/s] 75%|███████▍  | 159/213 [01:55<00:39,  1.37it/s] 75%|███████▌  | 160/213 [01:56<00:38,  1.37it/s] 76%|███████▌  | 161/213 [01:57<00:37,  1.37it/s] 76%|███████▌  | 162/213 [01:58<00:37,  1.36it/s] 77%|███████▋  | 163/213 [01:58<00:36,  1.36it/s] 77%|███████▋  | 164/213 [01:59<00:35,  1.36it/s] 77%|███████▋  | 165/213 [02:00<00:35,  1.37it/s] 78%|███████▊  | 166/213 [02:01<00:34,  1.37it/s] 78%|███████▊  | 167/213 [02:01<00:33,  1.37it/s] 79%|███████▉  | 168/213 [02:02<00:32,  1.37it/s] 79%|███████▉  | 169/213 [02:03<00:32,  1.37it/s] 80%|███████▉  | 170/213 [02:04<00:31,  1.37it/s] 80%|████████  | 171/213 [02:04<00:30,  1.37it/s] 81%|████████  | 172/213 [02:05<00:29,  1.37it/s] 81%|████████  | 173/213 [02:06<00:29,  1.37it/s] 82%|████████▏ | 174/213 [02:06<00:28,  1.37it/s] 82%|████████▏ | 175/213 [02:07<00:27,  1.37it/s] 83%|████████▎ | 176/213 [02:08<00:27,  1.36it/s] 83%|████████▎ | 177/213 [02:09<00:26,  1.36it/s] 84%|████████▎ | 178/213 [02:09<00:25,  1.36it/s] 84%|████████▍ | 179/213 [02:10<00:24,  1.36it/s] 85%|████████▍ | 180/213 [02:11<00:24,  1.37it/s] 85%|████████▍ | 181/213 [02:12<00:23,  1.37it/s] 85%|████████▌ | 182/213 [02:12<00:22,  1.37it/s] 86%|████████▌ | 183/213 [02:13<00:21,  1.36it/s] 86%|████████▋ | 184/213 [02:14<00:21,  1.36it/s] 87%|████████▋ | 185/213 [02:15<00:20,  1.36it/s] 87%|████████▋ | 186/213 [02:15<00:19,  1.36it/s] 88%|████████▊ | 187/213 [02:16<00:19,  1.36it/s] 88%|████████▊ | 188/213 [02:17<00:18,  1.36it/s] 89%|████████▊ | 189/213 [02:17<00:17,  1.37it/s] 89%|████████▉ | 190/213 [02:18<00:17,  1.35it/s] 90%|████████▉ | 191/213 [02:19<00:16,  1.35it/s] 90%|█████████ | 192/213 [02:20<00:15,  1.36it/s] 91%|█████████ | 193/213 [02:20<00:14,  1.36it/s] 91%|█████████ | 194/213 [02:21<00:13,  1.36it/s] 92%|█████████▏| 195/213 [02:22<00:13,  1.36it/s] 92%|█████████▏| 196/213 [02:23<00:12,  1.36it/s] 92%|█████████▏| 197/213 [02:23<00:11,  1.35it/s] 93%|█████████▎| 198/213 [02:24<00:11,  1.35it/s] 93%|█████████▎| 199/213 [02:25<00:10,  1.36it/s] 94%|█████████▍| 200/213 [02:26<00:09,  1.36it/s] 94%|█████████▍| 201/213 [02:26<00:08,  1.36it/s] 95%|█████████▍| 202/213 [02:27<00:08,  1.37it/s] 95%|█████████▌| 203/213 [02:28<00:07,  1.37it/s] 96%|█████████▌| 204/213 [02:28<00:06,  1.36it/s] 96%|█████████▌| 205/213 [02:29<00:05,  1.36it/s] 97%|█████████▋| 206/213 [02:30<00:05,  1.36it/s] 97%|█████████▋| 207/213 [02:31<00:04,  1.37it/s] 98%|█████████▊| 208/213 [02:31<00:03,  1.37it/s] 98%|█████████▊| 209/213 [02:32<00:02,  1.37it/s] 99%|█████████▊| 210/213 [02:33<00:02,  1.37it/s] 99%|█████████▉| 211/213 [02:34<00:01,  1.37it/s]100%|█████████▉| 212/213 [02:34<00:00,  1.64it/s][INFO|integration_utils.py:722] 2024-11-13 15:25:56,354 >> Automatic Weights & Biases logging enabled, to disable set os.environ["WANDB_DISABLED"] = "true"
wandb: Currently logged in as: mparadhana. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.6 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /home/amohanpa/transformers/examples/pytorch/audio-classification/wandb/run-20241113_152557-vbtgec9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-microwave-2311
wandb: ⭐️ View project at https://wandb.ai/mparadhana/huggingface
wandb: 🚀 View run at https://wandb.ai/mparadhana/huggingface/runs/vbtgec9j
100%|██████████| 213/213 [02:38<00:00,  1.35it/s]
[INFO|modelcard.py:452] 2024-11-13 15:26:00,117 >> Dropping the following result as it does not have all the necessary fields:
{'task': {'name': 'Audio Classification', 'type': 'audio-classification'}, 'dataset': {'name': 'superb', 'type': 'superb', 'config': 'ks', 'split': 'validation', 'args': 'ks'}}
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
layer num 0
head_list None
layer num 1
head_list None
layer num 2
head_list None
layer num 3
head_list None
return_dict True
Loss_local_Mean 0.0
***** eval metrics *****
  eval_accuracy           =     0.6209
  eval_loss               =     1.5368
  eval_runtime            = 0:02:38.21
  eval_samples_per_second =     42.966
  eval_steps_per_second   =      1.346
Traceback (most recent call last):
  File "/home/amohanpa/transformers/examples/pytorch/audio-classification/run_audio_classification.py", line 565, in <module>
    main()
  File "/home/amohanpa/transformers/examples/pytorch/audio-classification/run_audio_classification.py", line 561, in main
    print(loss_value)
UnboundLocalError: local variable 'loss_value' referenced before assignment
wandb: - 0.012 MB of 0.012 MB uploadedwandb: \ 0.012 MB of 0.012 MB uploadedwandb: | 0.039 MB of 0.039 MB uploaded (0.001 MB deduped)wandb: / 0.056 MB of 0.056 MB uploaded (0.001 MB deduped)wandb: 
wandb: Run history:
wandb:           eval/accuracy ▁
wandb:               eval/loss ▁
wandb:            eval/runtime ▁
wandb: eval/samples_per_second ▁
wandb:   eval/steps_per_second ▁
wandb:       train/global_step ▁
wandb: 
wandb: Run summary:
wandb:           eval/accuracy 0.62092
wandb:               eval/loss 1.53679
wandb:            eval/runtime 158.2175
wandb: eval/samples_per_second 42.966
wandb:   eval/steps_per_second 1.346
wandb:       train/global_step 0
wandb: 
wandb: 🚀 View run jolly-microwave-2311 at: https://wandb.ai/mparadhana/huggingface/runs/vbtgec9j
wandb: ️⚡ View job at https://wandb.ai/mparadhana/huggingface/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjQ1NzgyNzY3MQ==/version_details/v10
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241113_152557-vbtgec9j/logs
